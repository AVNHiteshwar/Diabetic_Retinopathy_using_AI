{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
      "Downloading opencv_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl (35.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.4/35.4 MB\u001b[0m \u001b[31m903.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 28099 invalid image filename(s) in x_col=\"Image\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 7027 invalid image filename(s) in x_col=\"Image\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 133\u001b[0m\n\u001b[1;32m    131\u001b[0m real_images \u001b[38;5;241m=\u001b[39m batch  \u001b[38;5;66;03m# Only unpack the input images, ignore the labels\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Process real_images and train your models\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m real_images \u001b[38;5;241m=\u001b[39m \u001b[43mreal_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m(batch_size, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Train Discriminator\u001b[39;00m\n\u001b[1;32m    135\u001b[0m noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, (batch_size, latent_dim))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Reshape, Conv2DTranspose, Conv2D, MaxPooling2D, BatchNormalization, Activation, Add, Multiply, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from skimage import exposure, filters\n",
    "import cv2\n",
    "\n",
    "# Load and preprocess real retinal images\n",
    "train_dir = \"/Users/hiteshwaralavala/Desktop/data_set_1/train\"\n",
    "test_dir = \"/Users/hiteshwaralavala/Desktop/data_set_1/test\"\n",
    "image_size = (64, 64)\n",
    "batch_size = 8\n",
    "\n",
    "train_csv = \"/Users/hiteshwaralavala/Desktop/igb_dataset_1/train.csv\"\n",
    "test_csv = \"/Users/hiteshwaralavala/Desktop/igb_dataset_1/test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)\n",
    "\n",
    "# Define function to preprocess image\n",
    "def preprocess_image(img):\n",
    "    # Gaussian blur\n",
    "    blurred_img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    # Histogram equalization\n",
    "    equalized_img = exposure.equalize_hist(blurred_img)\n",
    "    return equalized_img\n",
    "\n",
    "# Create ImageDataGenerator with preprocessing function\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    preprocessing_function=preprocess_image\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    preprocessing_function=preprocess_image\n",
    ")\n",
    "\n",
    "# Define train and test generators using flow_from_dataframe\n",
    "# Define train and test generators using flow_from_dataframe\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    directory=train_dir,\n",
    "    x_col=\"Image\",  # Column containing image filenames\n",
    "    y_col=\"Label\",  # Column containing labels\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Changed class_mode to \"categorical\"\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    directory=test_dir,\n",
    "    x_col=\"Image\",  # Column containing image filenames\n",
    "    y_col=\"Label\",  # Column containing labels\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Changed class_mode to \"categorical\"\n",
    "    shuffle=False  # No need to shuffle test data\n",
    ")\n",
    "\n",
    "# Define Squeeze-and-Excitation (SE) block\n",
    "def se_block(input_tensor, ratio=16):\n",
    "    num_channels = input_tensor.shape[-1]\n",
    "    se = GlobalAveragePooling2D()(input_tensor)\n",
    "    se = Dense(num_channels // ratio, activation='relu')(se)\n",
    "    se = Dense(num_channels, activation='sigmoid')(se)\n",
    "    return Multiply()([input_tensor, se])\n",
    "\n",
    "# Define Discriminator architecture\n",
    "def build_discriminator(input_shape=(64, 64, 3)):\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Conv2D(128, (3, 3), strides=(2, 2), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define Generator architecture\n",
    "def build_generator(latent_dim):\n",
    "    model = Sequential([\n",
    "        Dense(8 * 8 * 256, input_dim=latent_dim),\n",
    "        Reshape((8, 8, 256)),\n",
    "        Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Conv2DTranspose(3, (3, 3), strides=(2, 2), padding='same', activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Instantiate Discriminator and Generator\n",
    "latent_dim = 100\n",
    "discriminator = build_discriminator()\n",
    "generator = build_generator(latent_dim)\n",
    "\n",
    "# Define GAN model\n",
    "discriminator.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = tf.keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = Model(gan_input, gan_output)\n",
    "gan.compile(optimizer=Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
    "\n",
    "# Train the GAN\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_generator:\n",
    "        real_images = batch  # Only unpack the input images, ignore the labels\n",
    "        # Process real_images and train your models\n",
    "        real_images = real_images.reshape(batch_size, 64, 64, 3)\n",
    "        # Train Discriminator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        fake_images = generator.predict(noise)\n",
    "        discriminator_loss_real = discriminator.train_on_batch(real_images, np.ones((batch_size, 1)))\n",
    "        discriminator_loss_fake = discriminator.train_on_batch(fake_images, np.zeros((batch_size, 1)))\n",
    "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
    "\n",
    "        # Train Generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        generator_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Batch {batch}/{len(train_generator)}, \"\n",
    "              f\"Discriminator Loss: {discriminator_loss}, Generator Loss: {generator_loss}\")\n",
    "\n",
    "# Fine-tune the InceptionV3 model with SE block\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = se_block(x)  # Add SE block\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator)\n",
    ")\n",
    "\n",
    "# Save the final model\n",
    "model.save(\"final-1_diabetic_retinopathy_detection_model.h5\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of real_images: (8, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of real_images:\", real_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
