{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting and CSV creation complete.\n",
      "Train data:  2929\n",
      "Test data:  733\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "# Set the path to your data directory\n",
    "data_dir = r\"/Users/hiteshwaralavala/Desktop/new exp/colored_images\"\n",
    "dest_dir = r\"/Users/hiteshwaralavala/Desktop/new_Exp_!\"\n",
    "\n",
    "# Set the ratio for splitting data into train and test\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Create train and test directories\n",
    "train_dir = os.path.join(dest_dir, 'train')\n",
    "test_dir = os.path.join(dest_dir, 'test')\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Create CSV files to store image names and labels\n",
    "train_csv = os.path.join(dest_dir, 'train.csv')\n",
    "test_csv = os.path.join(dest_dir, 'test.csv')\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "# Iterate through each label folder\n",
    "for label in os.listdir(data_dir):\n",
    "    if os.path.isdir(os.path.join(data_dir, label)):\n",
    "        images = os.listdir(os.path.join(data_dir, label))\n",
    "        random.shuffle(images)\n",
    "        num_train = int(len(images) * train_ratio)\n",
    "        \n",
    "        # Copy images to train folder and add to train CSV\n",
    "        for img in images[:num_train]:\n",
    "            src_path = os.path.join(data_dir, label, img)\n",
    "            dst_path = os.path.join(train_dir, f\"{label}_{img}\")\n",
    "            copyfile(src_path, dst_path)\n",
    "            train_data.append((f\"{label}_{img}\", label))\n",
    "        \n",
    "        # Copy images to test folder and add to test CSV\n",
    "        for img in images[num_train:]:\n",
    "            src_path = os.path.join(data_dir, label, img)\n",
    "            dst_path = os.path.join(test_dir, f\"{label}_{img}\")\n",
    "            copyfile(src_path, dst_path)\n",
    "            test_data.append((f\"{label}_{img}\", label))\n",
    "\n",
    "# Write train and test CSV files\n",
    "train_df = pd.DataFrame(train_data, columns=['Image', 'Label'])\n",
    "train_df.to_csv(train_csv, index=False)\n",
    "\n",
    "test_df = pd.DataFrame(test_data, columns=['Image', 'Label'])\n",
    "test_df.to_csv(test_csv, index=False)\n",
    "\n",
    "print(\"Data splitting and CSV creation complete.\")\n",
    "print(\"Train data: \",str(len(train_data)))\n",
    "print(\"Test data: \",str(len(test_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mild: 370 images\n",
      "Moderate: 999 images\n",
      "No_DR: 1805 images\n",
      "Proliferate_DR: 295 images\n",
      "Severe: 193 images\n",
      "Total: 3662 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List of labels\n",
    "labels = [ 'Mild', 'Moderate', 'No_DR', 'Proliferate_DR', 'Severe']\n",
    "\n",
    "# Dictionary to store counts\n",
    "image_counts = {}\n",
    "\n",
    "# Iterate through each label folder and count images\n",
    "for label in labels:\n",
    "    label_dir = os.path.join(data_dir, label)\n",
    "    if os.path.isdir(label_dir):\n",
    "        images = os.listdir(label_dir)\n",
    "        image_counts[label] = len(images)\n",
    "    else:\n",
    "        image_counts[label] = 0\n",
    "\n",
    "# Print counts for each label\n",
    "for label, count in image_counts.items():\n",
    "    print(f\"{label}: {count} images\")\n",
    "\n",
    "# Calculate total count\n",
    "total_count = sum(image_counts.values())\n",
    "print(f\"Total: {total_count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2929 validated image filenames belonging to 5 classes.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 631ms/step - accuracy: 0.5868 - loss: 1.1431\n",
      "Epoch 2/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 630ms/step - accuracy: 0.7330 - loss: 0.7576\n",
      "Epoch 3/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 636ms/step - accuracy: 0.7318 - loss: 0.6978\n",
      "Epoch 4/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 642ms/step - accuracy: 0.7376 - loss: 0.6947\n",
      "Epoch 5/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 634ms/step - accuracy: 0.7309 - loss: 0.6976\n",
      "Epoch 6/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 637ms/step - accuracy: 0.7546 - loss: 0.6526\n",
      "Epoch 7/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 642ms/step - accuracy: 0.7552 - loss: 0.6451\n",
      "Epoch 8/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 638ms/step - accuracy: 0.7747 - loss: 0.6049\n",
      "Epoch 9/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 636ms/step - accuracy: 0.7730 - loss: 0.5921\n",
      "Epoch 10/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 632ms/step - accuracy: 0.7660 - loss: 0.6144\n",
      "Epoch 11/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 630ms/step - accuracy: 0.7833 - loss: 0.5985\n",
      "Epoch 12/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 633ms/step - accuracy: 0.7782 - loss: 0.5930\n",
      "Epoch 13/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 645ms/step - accuracy: 0.7718 - loss: 0.6035\n",
      "Epoch 14/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 629ms/step - accuracy: 0.7793 - loss: 0.5712\n",
      "Epoch 15/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 636ms/step - accuracy: 0.7996 - loss: 0.5518\n",
      "Epoch 16/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 631ms/step - accuracy: 0.7857 - loss: 0.5700\n",
      "Epoch 17/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 633ms/step - accuracy: 0.7842 - loss: 0.5731\n",
      "Epoch 18/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 634ms/step - accuracy: 0.7766 - loss: 0.5558\n",
      "Epoch 19/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 656ms/step - accuracy: 0.7849 - loss: 0.5438\n",
      "Epoch 20/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 646ms/step - accuracy: 0.7823 - loss: 0.5726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Reshape, Multiply, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, Multiply\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def squeeze_excite_block(input_tensor, ratio=16):\n",
    "    # Get the number of channels\n",
    "    channels = int(input_tensor.shape[-1])\n",
    "\n",
    "    # Reshape the input tensor to ensure it has the correct shape\n",
    "    x = Reshape((1, 1, channels))(input_tensor)\n",
    "\n",
    "    # Squeeze operation\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Excitation operation\n",
    "    x = Dense(channels // ratio, activation='relu')(x)\n",
    "    x = Dense(channels, activation='sigmoid')(x)\n",
    "\n",
    "    # Scale input features\n",
    "    x = Multiply()([input_tensor, x])\n",
    "\n",
    "    return x\n",
    "\n",
    "# Define custom preprocessing function for Gaussian noise\n",
    "def apply_gaussian_noise(image):\n",
    "    noise = np.random.normal(loc=0, scale=0.1, size=image.shape)\n",
    "    return image + noise\n",
    "\n",
    "# Set paths\n",
    "train_dir = \"/Users/hiteshwaralavala/Desktop/new_exp_2/train\"\n",
    "train_csv = \"/Users/hiteshwaralavala/Desktop/new_exp_2/train.csv\"\n",
    "image_size = (224, 224)  # DenseNet input size\n",
    "num_classes = 5\n",
    "\n",
    "# Iterate through each image in the train folder and resize\n",
    "for filename in os.listdir(train_dir):\n",
    "    if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(train_dir, filename)\n",
    "        with Image.open(image_path) as img:\n",
    "            img_resized = img.resize(image_size)\n",
    "            img_resized.save(image_path)\n",
    "\n",
    "# Read train CSV file\n",
    "train_data = pd.read_csv(train_csv)\n",
    "\n",
    "# Create ImageDataGenerator with Gaussian noise preprocessing and data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    preprocessing_function=apply_gaussian_noise,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Flow from directory with train_data\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_data,\n",
    "    directory=train_dir,\n",
    "    x_col='Image',\n",
    "    y_col='Label',\n",
    "    target_size=image_size,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load DenseNet model without top layers\n",
    "base_model = DenseNet121(weights='/Users/hiteshwaralavala/Desktop/new_exp_2/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom top layers with SE block\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = squeeze_excite_block(x)  # Add SE block\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Add Dropout regularization\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze all layers of DenseNet base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(train_generator, epochs=20)\n",
    "\n",
    "# Save model with .h5 extension\n",
    "model.save('/Users/hiteshwaralavala/Desktop/new_exp_2/densnet_optimised_model_with_dropout_and_gaussian.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 733 validated image filenames belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 616ms/step - accuracy: 0.6230 - loss: 0.9477\n",
      "Test Accuracy: 0.7776262164115906\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 658ms/step\n",
      "Precision: 0.7611542838185447\n",
      "Recall: 0.7776261937244202\n",
      "F1 Score: 0.7693020768081917\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Set paths\n",
    "test_dir = r\"/Users/hiteshwaralavala/Desktop/new_exp_2/test\"\n",
    "test_csv = r\"/Users/hiteshwaralavala/Desktop/new_exp_2/test.csv\"\n",
    "image_size = (224, 224)  # DenseNet input size\n",
    "num_classes = 5\n",
    "\n",
    "# Set the target size\n",
    "target_size = (224, 224)\n",
    "\n",
    "# Iterate through each image in the train folder\n",
    "for filename in os.listdir(test_dir):\n",
    "    if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(test_dir, filename)\n",
    "        with Image.open(image_path) as img:\n",
    "            img_resized = img.resize(target_size)\n",
    "            img_resized.save(image_path)\n",
    "\n",
    "\n",
    "# Read test CSV file\n",
    "test_data = pd.read_csv(test_csv)\n",
    "\n",
    "# Create ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow from directory with test_data\n",
    "test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=test_data,\n",
    "    directory=test_dir,\n",
    "    x_col='Image',\n",
    "    y_col='Label',\n",
    "    target_size=image_size,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Important to match predictions with actual labels\n",
    ")\n",
    "\n",
    "# Load trained DenseNet model\n",
    "model = load_model('/Users/hiteshwaralavala/Desktop/new_exp_2/densnet_optimised_model_with_dropout_and_gaussian.h5')\n",
    "\n",
    "# Evaluate model on test data\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "# Get predicted labels\n",
    "y_pred_prob = model.predict(test_generator)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert actual labels to numeric\n",
    "label_map = {label: i for i, label in enumerate(test_generator.class_indices)}\n",
    "y_true = test_data['Label'].map(label_map).values\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
